{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/dist-packages')\n",
    "sys.path.append('/usr/local/lib/python3.5/dist-packages')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_dict\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_name = '/data2'\n",
    "#create_dict.clean_obj(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 freeze | grep PyWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pywavefront\n",
    "#mesh2 = pywavefront.Wavefront('/home/.schramm/Documents/3d_retrieval/data/02747177/8bdea15ae5d929d0a2eb129d649f68cf/models/model_normalized.obj', collect_faces='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/data'\n",
    "suffix = '_test' #suffix will append data_trainxxxx.json\n",
    "max_elements_per_class = 50\n",
    "#create_dict.create_dictionary(input_folder, max_elements_per_class, suffix, points_per_object=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SiameseNet\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "net = SiameseNet.SiameseNet(batch_size, num_points=1500)\n",
    "suffix = 'CT_2000p' # comment in if not coming from generating the dataset\n",
    "#suffix = '_test'\n",
    "#path_to_params = \"models/autoencoder5_100epochs_BS16_CT_Gewichtung_text*1_shape*200_BS32.pt\" # if file does not exist or is empty it starts from untrained and later saves to the file\n",
    "path_to_params = \"models/testtt.pt\"\n",
    "\n",
    "# shift to GPU if available\n",
    "\n",
    "net.to(device)\n",
    "working_dir = os.getcwd()\n",
    "data_dir_train = os.path.join(working_dir, 'data_train'+suffix+'.json')\n",
    "data_dir_val = os.path.join(working_dir, 'data_val'+suffix+'.json')\n",
    "class_dir = os.path.join(working_dir, 'class_dict'+suffix+'.json')\n",
    "\n",
    "path_to_hidden = str(path_to_params[:-3] + '_hidden.pt')\n",
    "#if os.path.isfile(path_to_hidden):\n",
    "#    net.hidden = torch.load(path_to_hidden)\n",
    "if os.path.isfile(path_to_params):\n",
    "    if os.stat(path_to_params).st_size != 0:\n",
    "        net.load_state_dict(torch.load(path_to_params, map_location=device))  #Loads pretrained net if file exists and if not empty\n",
    "else:\n",
    "    open(path_to_params, \"x\") #Creates parameter file if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#execute for tensorboard\n",
    "tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "#writer_suffix = 'autoencoder5_100epochs_BS16_CT_Gewichtung_text*1_shape*200_BS32'\n",
    "writer_suffix = 'testrr'\n",
    "margin = 0.5\n",
    "num_epochs = 100\n",
    "print_batch = 10\n",
    "lr = 2e-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNet.train(net, num_epochs, margin, lr, print_batch, \n",
    "                       data_dir_train, data_dir_val, writer_suffix, path_to_params, working_dir, class_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.5\n",
    "writer_suffix = 'testrr_Val_images'\n",
    "metric=[]\n",
    "\n",
    "# average metric of k runs\n",
    "k=1\n",
    "for i in range(k):\n",
    "    metric.append(SiameseNet.val(net, margin, data_dir_val, writer_suffix, working_dir, class_dir, k=5,  images=True))\n",
    "\n",
    "scores=np.asarray(metric)*100\n",
    "scores2 = np.mean(scores, axis=0)\n",
    "print('averaged scores are:')\n",
    "#print(scores2)\n",
    "#print('with standard deviation:')\n",
    "var = np.std(scores, axis=0)\n",
    "#print(var)\n",
    "print()\n",
    "print('rr@1:', np.round(scores2[0],4), '+-',np.round(var[0]*1.96, 4))\n",
    "print('rr@5:', np.round(scores2[1],4), '+-',np.round(var[1]*1.96, 4))\n",
    "print('rr@10:', np.round(scores2[2],4), '+-',np.round(var[2]*1.96, 4))\n",
    "print('NDCG@5:', np.round(scores2[3],4), '+-',np.round(var[3]*1.96, 4))\n",
    "print('NDCG@10:', np.round(scores2[4],4), '+-',np.round(var[4]*1.96, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, ids, shape, description = SiameseNet.retrieval(net, data_dir_val, working_dir, print_nn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.retrieve_images(y_pred, ids, data_dir_val, class_dir, num_KNN=5, max_show=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'a wooden craft chair'\n",
    "#sentence = input(\"Enter sentence\")\n",
    "utils.retrieve_one_sentence(net, data_dir_val, working_dir, sentence, class_dir, y_pred , ids, shape, num_KNN=5,samples_pointcould=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr1, rr5, rr10, ndcg5, ndcg10 = SiameseNet.test(net, margin, data_dir_val, working_dir)\n",
    "print('retrieval performance measures:')\n",
    "print('rr@1', np.round((rr1*100),4))\n",
    "print('rr@5', np.round((rr5*100),4))\n",
    "print('rr@10', np.round((rr10*100),4))\n",
    "print('NDCG@5', np.round((ndcg5*100),4))\n",
    "print('NDCG@10', np.round((ndcg10*100),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
