{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/.schramm/Documents/3d_retrieval',\n",
       " '/opt/anaconda3/lib/python37.zip',\n",
       " '/opt/anaconda3/lib/python3.7',\n",
       " '/opt/anaconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/anaconda3/lib/python3.7/site-packages',\n",
       " '/opt/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/.schramm/.ipython',\n",
       " '/usr/local/lib/python2.7/dist-packages',\n",
       " '/usr/local/lib/python2.7/dist-packages',\n",
       " '/usr/local/lib/python2.7/dist-packages']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/dist-packages')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_dict\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '/data2'\n",
    "#create_dict.clean_obj(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_folder = '/data_cleaned'\n",
    "suffix = '_test' #suffix will append data_trainxxxx.json\n",
    "max_elements_per_class = 5\n",
    "create_dict.create_dictionary(input_folder, max_elements_per_class, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SiameseNet\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 2\n",
    "net = SiameseNet.SiameseNet(batch_size)\n",
    "suffix = '_test' # comment in if not coming from generating the dataset\n",
    "path_to_params = \"models/test.pt\" # if file does not exist or is empty it starts from untrained and later saves to the file\n",
    "\n",
    "# shift to GPU if available\n",
    "\n",
    "net.to(device)\n",
    "working_dir = os.getcwd()\n",
    "data_dir_train = os.path.join(working_dir, 'data_train'+suffix+'.json')\n",
    "data_dir_val = os.path.join(working_dir, 'data_val'+suffix+'.json')\n",
    "class_dir = os.path.join(working_dir, 'class_dict'+suffix+'.json')\n",
    "\n",
    "if os.path.isfile(path_to_params):\n",
    "    if os.stat(path_to_params).st_size != 0:\n",
    "        net.load_state_dict(torch.load(path_to_params))  #Loads pretrained net if file exists and if not empty\n",
    "else:\n",
    "    open(path_to_params, \"x\") #Creates parameter file if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#execute for tensorboard\n",
    "tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "writer_suffix = 'testing'\n",
    "margin = 0.5\n",
    "num_epochs = 1\n",
    "print_batch = 1\n",
    "lr = 0.0001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 train triplets generated -> return dict\n",
      "Loaded 5032 word vectors.\n",
      "Number of training triplets: 63\n",
      "[1,     2] loss: 2.713\n",
      "[1,     3] loss: 0.194\n",
      "[1,     4] loss: 0.406\n",
      "[1,     5] loss: 0.703\n",
      "[1,     6] loss: 0.250\n",
      "[1,     7] loss: 0.817\n",
      "[1,     8] loss: 0.240\n",
      "[1,     9] loss: 1.344\n",
      "[1,    10] loss: 3.194\n",
      "[1,    11] loss: 0.250\n",
      "[1,    12] loss: 0.255\n",
      "[1,    13] loss: 0.251\n",
      "[1,    14] loss: 1.925\n",
      "[1,    15] loss: 0.593\n",
      "[1,    16] loss: 0.826\n",
      "[1,    17] loss: 1.841\n",
      "[1,    18] loss: 0.250\n",
      "[1,    19] loss: 0.339\n",
      "[1,    20] loss: 0.248\n",
      "[1,    21] loss: 0.254\n",
      "[1,    22] loss: 1.997\n",
      "[1,    23] loss: 0.521\n",
      "[1,    24] loss: 0.250\n",
      "[1,    25] loss: 0.664\n",
      "[1,    26] loss: 1.453\n",
      "[1,    27] loss: 1.089\n",
      "[1,    28] loss: 1.330\n",
      "[1,    29] loss: 1.762\n",
      "[1,    30] loss: 1.090\n",
      "[1,    31] loss: 0.240\n",
      "[1,    32] loss: 0.252\n",
      "[1,    33] loss: 0.246\n",
      "[1,    34] loss: 0.800\n",
      "[1,    35] loss: 1.351\n",
      "[1,    36] loss: 0.330\n",
      "[1,    37] loss: 0.301\n",
      "[1,    38] loss: 0.251\n",
      "[1,    39] loss: 0.250\n",
      "[1,    40] loss: 0.248\n",
      "[1,    41] loss: 0.596\n",
      "[1,    42] loss: 0.241\n",
      "[1,    43] loss: 0.250\n",
      "[1,    44] loss: 0.250\n",
      "[1,    45] loss: 0.250\n",
      "[1,    46] loss: 0.250\n",
      "[1,    47] loss: 0.252\n",
      "[1,    48] loss: 1.263\n",
      "[1,    49] loss: 0.687\n",
      "[1,    50] loss: 1.848\n",
      "[1,    51] loss: 2.755\n",
      "[1,    52] loss: 0.252\n",
      "[1,    53] loss: 0.275\n",
      "[1,    54] loss: 0.250\n",
      "[1,    55] loss: 0.576\n",
      "[1,    56] loss: 0.251\n",
      "[1,    57] loss: 1.144\n",
      "[1,    58] loss: 0.384\n",
      "[1,    59] loss: 1.284\n",
      "[1,    60] loss: 0.802\n",
      "[1,    61] loss: 0.774\n",
      "[1,    62] loss: 0.251\n",
      "[1,    63] loss: 0.341\n",
      "8 val triplets generated\n",
      "Loaded 5032 word vectors.\n",
      "Doing Evaluation with 8.0 validation triplets\n",
      "Validation Loss: 2.5993183255195618\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = SiameseNet.train(net, num_epochs, margin, lr, print_batch, \n",
    "                       data_dir_train, data_dir_val, writer_suffix, path_to_params, working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.5\n",
    "writer_suffix = 'Val'\n",
    "SiameseNet.val(net, margin, data_dir_val, writer_suffix, working_dir, class_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 val triplets generated\n",
      "Loaded 5032 word vectors.\n",
      "Number of validation triplets: 4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-945d1f795d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmargin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiameseNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworking_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/3d_retrieval/SiameseNet.py\u001b[0m in \u001b[0;36mretrieval\u001b[0;34m(net, data_dir_val, working_dir)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "y_true, y_pred, ids, shape, description = SiameseNet.retrieval(net, data_dir_val, working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_KNN = 4\n",
    "max_show = 3\n",
    "utils.retrieve_images(y_pred, ids, data_dir_val, class_dir, num_KNN, max_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
