{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_dict\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '/data'\n",
    "create_dict.clean_obj(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_folder = '/data_cleaned'\n",
    "suffix = '_test' #suffix will append data_trainxxxx.json\n",
    "max_elements_per_class = 5\n",
    "create_dict.create_dictionary(input_folder, max_elements_per_class, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SiameseNet\n",
    "\n",
    "batch_size = 2\n",
    "net = SiameseNet.SiameseNet(batch_size)\n",
    "\n",
    "\n",
    "path_to_params = \"models/new_2.pt\" # if file does not exist or is empty it starts from untrained and later saves to the file\n",
    "\n",
    "working_dir = os.getcwd()\n",
    "data_dir_train = os.path.join(working_dir, 'data_train_test.json')\n",
    "data_dir_val = os.path.join(working_dir, 'data_val_test.json')\n",
    "class_dir = os.path.join(working_dir, 'class_dict_test.json')\n",
    "\n",
    "if os.path.isfile(path_to_params):\n",
    "    if os.stat(path_to_params).st_size != 0:\n",
    "        net.load_state_dict(torch.load(path_to_params))  #Loads pretrained net if file exists and if not empty\n",
    "else:\n",
    "    open(path_to_params, \"x\") #Creates parameter file if it does not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#execute for tensorboard\n",
    "tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "writer_suffix = 'testing'\n",
    "margin = 0.5\n",
    "num_epochs = 1\n",
    "print_batch = 1\n",
    "lr = 0.0001\n",
    "print_batch = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = SiameseNet.train(net, num_epochs, margin, lr, batch_size, print_batch, \n",
    "                       data_dir_train, data_dir_val, writer_suffix, path_to_params, working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_suffix = 'Val'\n",
    "margin = 0.5\n",
    "SiameseNet.val(net, margin,batch_size, data_dir_val, writer_suffix, working_dir, class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 val triplets generated\n",
      "Loaded 5032 word vectors.\n",
      "Number of validation triplets: 4\n",
      "0 [7 0 3 6 5]\n",
      "1 [7 0 3 6 5]\n",
      "2 [7 0 3 6 5]\n",
      "3 [7 0 3 6 5]\n",
      "4 [7 0 3 6 5]\n",
      "5 [7 0 3 6 5]\n",
      "6 [7 0 3 6 5]\n",
      "7 [7 0 3 6 5]\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred, ids, shape, description = SiameseNet.retrieval(net, batch_size, data_dir_val, working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: ID: cb38405e384c79c05e4e385b035691bb  Description: ['this', 'is', 'a', 'brown', 'tub']\n",
      "1N: ID a8cfed0a1b9451c9d213467246722099\n",
      "2N: ID cb38405e384c79c05e4e385b035691bb\n",
      "Sample: ID: 555f9430c2ca273ccb2a965e75be701c  Description: ['this', 'is', 'a', 'brown', 'and', 'red', 'table']\n",
      "1N: ID a8cfed0a1b9451c9d213467246722099\n",
      "2N: ID cb38405e384c79c05e4e385b035691bb\n",
      "Sample: ID: 2388c99892c2185268d1b9a1d97e2846  Description: ['this', 'is', 'up', 'lamp', 'around', 'a', 'blue', 'pole', 'with', 'no', 'lamp', 'shade']\n",
      "1N: ID a8cfed0a1b9451c9d213467246722099\n",
      "2N: ID cb38405e384c79c05e4e385b035691bb\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir_val, 'r') as fp:\n",
    "    data_val = json.load(fp)\n",
    "    \n",
    "max_show = 3\n",
    "for i, key in enumerate(ids):\n",
    "    if (i>=max_show):\n",
    "        break\n",
    "    print(\"Sample: ID:\", key, \" Description:\", data_val[key][1])\n",
    "    print(\"1N: ID\", ids[y_pred[i][0]]) #todo get picture\n",
    "    print(\"2N: ID\", ids[y_pred[i][1]]) #todo get picture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.42531216e-01, -2.44442120e-01, -5.62980413e-01,  6.71928823e-02,\n",
       "       -3.69043648e-03, -1.13549322e-01, -1.06528312e-01,  3.05844367e-01,\n",
       "       -1.85883850e-01,  4.41846699e-02,  2.56006956e-01, -4.04928744e-01,\n",
       "       -6.36332810e-01, -4.26982403e-01,  1.83869228e-01, -2.09941253e-01,\n",
       "        2.89093375e-01, -5.21423221e-02,  4.89547044e-01, -1.23760879e-01,\n",
       "       -1.79536551e-01,  3.48618686e-01, -4.47708845e-01, -2.24357158e-01,\n",
       "       -6.61359355e-02,  3.92145902e-01,  3.89361292e-01, -5.15017867e-01,\n",
       "       -5.12953281e-01, -2.44265512e-01, -2.21330132e-02,  5.53974807e-01,\n",
       "       -2.20499337e-01,  3.89540672e-01,  8.33313018e-02, -1.70693398e-01,\n",
       "       -1.79679096e-01,  2.02949196e-02,  7.37331901e-03, -1.86409280e-01,\n",
       "       -1.71399146e-01, -3.56023759e-01,  1.93251863e-01,  1.56679705e-01,\n",
       "       -1.04185998e-01,  8.57848525e-02, -5.08065641e-01, -2.64837295e-01,\n",
       "       -2.42297560e-01,  1.62949651e-01, -1.50813818e-01,  3.59568149e-01,\n",
       "        3.14387709e-01, -4.44019675e-01,  2.34958410e-01,  3.11574310e-01,\n",
       "        1.13466121e-01, -2.81490624e-01,  2.30455309e-01,  1.47963911e-02,\n",
       "        2.07590327e-01, -1.43511817e-01,  1.31492361e-01,  6.55048937e-02,\n",
       "        2.83590466e-01, -1.70319125e-01, -2.84233868e-01, -2.35172182e-01,\n",
       "       -6.20301962e-02,  4.63120304e-02, -1.62618533e-01, -2.99817324e-03,\n",
       "        1.04210883e-01,  2.95399070e-01,  4.29863364e-01,  2.75739521e-01,\n",
       "        2.20932588e-01,  4.26741332e-01, -4.03912738e-03,  3.07410866e-01,\n",
       "       -1.91461653e-01,  5.33570409e-01, -8.92395526e-03,  2.74879485e-01,\n",
       "        4.00926620e-02,  4.45467085e-02,  1.23586431e-01,  6.00123778e-04,\n",
       "        2.35795870e-01, -3.87654006e-01,  3.84458862e-02, -5.66608489e-01,\n",
       "       -3.51602256e-01, -1.08740464e-01, -5.33308983e-01, -1.04472414e-01,\n",
       "       -8.39186236e-02, -3.07971358e-01, -3.13952565e-01,  1.66854531e-01,\n",
       "        2.62298346e-01,  4.49474216e-01, -6.12091720e-01, -5.88217787e-02,\n",
       "       -1.09628402e-02, -9.97536778e-02,  1.29330665e-01,  2.10237741e-01,\n",
       "       -1.56641915e-01, -2.22248852e-01, -7.74374753e-02, -3.87959421e-01,\n",
       "        2.00146481e-01,  1.21116221e-01, -2.90103585e-01,  1.61465123e-01,\n",
       "       -4.19952385e-02,  1.58313662e-04, -4.54994887e-01, -3.17272872e-01,\n",
       "        1.09829098e-01,  1.63507722e-02,  2.14009926e-01,  7.94858783e-02,\n",
       "       -1.41588505e-02,  3.90834689e-01,  4.09599185e-01, -3.67074966e-01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2962560135206367\n",
      "1 4.076944862289302\n",
      "2 4.9953174082267555\n",
      "3 3.373268785272508\n",
      "4 3.526975381398004\n",
      "5 3.481387993434155\n",
      "6 3.4665262228577878\n",
      "7 3.131108571363356\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(i, np.linalg.norm(description[7]-shape[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
