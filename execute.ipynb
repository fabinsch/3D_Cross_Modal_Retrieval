{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ga96kub/3d_retrieval',\n",
       " '/opt/anaconda3/lib/python37.zip',\n",
       " '/opt/anaconda3/lib/python3.7',\n",
       " '/opt/anaconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/anaconda3/lib/python3.7/site-packages',\n",
       " '/opt/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/ga96kub/.ipython',\n",
       " '/usr/local/lib/python2.7/dist-packages',\n",
       " '/usr/local/lib/python3.5/dist-packages']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/dist-packages')\n",
    "sys.path.append('/usr/local/lib/python3.5/dist-packages')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_dict\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_name = '/data2'\n",
    "#create_dict.clean_obj(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 freeze | grep PyWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pywavefront\n",
    "#mesh2 = pywavefront.Wavefront('/home/.schramm/Documents/3d_retrieval/data/02747177/8bdea15ae5d929d0a2eb129d649f68cf/models/model_normalized.obj', collect_faces='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_folder = '/data'\n",
    "suffix = '_allClasses1000_points2500' #suffix will append data_trainxxxx.json\n",
    "max_elements_per_class = 1000\n",
    "create_dict.create_dictionary(input_folder, max_elements_per_class, suffix, points_per_object=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SiameseNet\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 16\n",
    "net = SiameseNet.SiameseNet(batch_size)\n",
    "suffix = '_allClasses1000_points2500' # comment in if not coming from generating the dataset\n",
    "path_to_params = \"models/_allCl1000_P2500_BS16_classLoss.pt\" # if file does not exist or is empty it starts from untrained and later saves to the file\n",
    "\n",
    "# shift to GPU if available\n",
    "\n",
    "net.to(device)\n",
    "working_dir = os.getcwd()\n",
    "data_dir_train = os.path.join(working_dir, 'data_train'+suffix+'.json')\n",
    "data_dir_val = os.path.join(working_dir, 'data_val'+suffix+'.json')\n",
    "class_dir = os.path.join(working_dir, 'class_dict'+suffix+'.json')\n",
    "\n",
    "if os.path.isfile(path_to_params):\n",
    "    if os.stat(path_to_params).st_size != 0:\n",
    "        net.load_state_dict(torch.load(path_to_params, map_location=device))  #Loads pretrained net if file exists and if not empty\n",
    "else:\n",
    "    open(path_to_params, \"x\") #Creates parameter file if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#execute for tensorboard\n",
    "tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "writer_suffix = 'allC1000_LRe-3_MR05_classLoss'\n",
    "margin = 0.5\n",
    "num_epochs = 100\n",
    "print_batch = 30\n",
    "lr = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5032 word vectors.\n",
      "Number of training triplets: 3733\n",
      "[1,    31] loss: 2.093\n",
      "[1,    61] loss: 1.437\n",
      "[1,    91] loss: 1.339\n",
      "[1,   121] loss: 1.336\n",
      "[1,   151] loss: 1.320\n",
      "[1,   181] loss: 1.317\n",
      "[1,   211] loss: 1.329\n",
      "[1,   241] loss: 1.286\n",
      "[1,   271] loss: 1.304\n",
      "[1,   301] loss: 1.299\n",
      "[1,   331] loss: 1.242\n",
      "[1,   361] loss: 1.239\n",
      "[1,   391] loss: 1.183\n",
      "[1,   421] loss: 1.167\n",
      "[1,   451] loss: 1.230\n",
      "Loaded 5032 word vectors.\n",
      "Doing Evaluation with 934 validation triplets\n",
      "Validation Loss: 1.5148091347053134\n",
      "Loaded 5032 word vectors.\n",
      "Number of training triplets: 3733\n",
      "[2,    31] loss: 1.225\n",
      "[2,    61] loss: 1.089\n",
      "[2,    91] loss: 1.113\n",
      "[2,   121] loss: 1.120\n",
      "[2,   151] loss: 1.132\n",
      "[2,   181] loss: 1.095\n",
      "[2,   211] loss: 1.118\n",
      "[2,   241] loss: 1.067\n",
      "[2,   271] loss: 1.061\n",
      "[2,   301] loss: 1.048\n",
      "[2,   331] loss: 1.011\n",
      "[2,   361] loss: 1.040\n",
      "[2,   391] loss: 1.001\n",
      "[2,   421] loss: 0.997\n",
      "[2,   451] loss: 1.023\n",
      "Loaded 5032 word vectors.\n",
      "Doing Evaluation with 934 validation triplets\n",
      "Validation Loss: 0.9984626358953016\n",
      "Loaded 5032 word vectors.\n",
      "Number of training triplets: 3733\n",
      "[3,    31] loss: 1.030\n",
      "[3,    61] loss: 0.969\n",
      "[3,    91] loss: 0.996\n",
      "[3,   121] loss: 0.980\n",
      "[3,   151] loss: 0.999\n",
      "[3,   181] loss: 1.025\n",
      "[3,   211] loss: 0.948\n",
      "[3,   241] loss: 1.022\n",
      "[3,   271] loss: 0.981\n",
      "[3,   301] loss: 0.967\n",
      "[3,   331] loss: 0.984\n",
      "[3,   361] loss: 0.986\n",
      "[3,   391] loss: 0.978\n",
      "[3,   421] loss: 0.968\n",
      "[3,   451] loss: 0.982\n",
      "Loaded 5032 word vectors.\n",
      "Doing Evaluation with 934 validation triplets\n",
      "Validation Loss: 0.9384736213190802\n",
      "Loaded 5032 word vectors.\n",
      "Number of training triplets: 3733\n",
      "[4,    31] loss: 0.981\n",
      "[4,    61] loss: 0.884\n",
      "[4,    91] loss: 0.891\n",
      "[4,   121] loss: 0.924\n",
      "[4,   151] loss: 0.923\n",
      "[4,   181] loss: 0.906\n",
      "[4,   211] loss: 0.881\n",
      "[4,   241] loss: 0.945\n",
      "[4,   271] loss: 0.899\n",
      "[4,   301] loss: 0.866\n",
      "[4,   331] loss: 0.857\n",
      "[4,   361] loss: 0.893\n",
      "[4,   391] loss: 0.932\n",
      "[4,   421] loss: 0.816\n",
      "[4,   451] loss: 0.819\n",
      "Loaded 5032 word vectors.\n",
      "Doing Evaluation with 934 validation triplets\n",
      "Validation Loss: 0.8423615128829561\n",
      "Loaded 5032 word vectors.\n",
      "Number of training triplets: 3733\n",
      "[5,    31] loss: 0.900\n",
      "[5,    61] loss: 0.798\n",
      "[5,    91] loss: 0.836\n",
      "[5,   121] loss: 0.777\n",
      "[5,   151] loss: 0.789\n",
      "[5,   181] loss: 0.801\n",
      "[5,   211] loss: 0.801\n",
      "[5,   241] loss: 0.775\n",
      "[5,   271] loss: 0.885\n",
      "[5,   301] loss: 0.818\n",
      "[5,   331] loss: 0.802\n",
      "[5,   361] loss: 0.729\n",
      "[5,   391] loss: 0.765\n",
      "[5,   421] loss: 0.721\n",
      "[5,   451] loss: 0.815\n",
      "Loaded 5032 word vectors.\n",
      "Doing Evaluation with 934 validation triplets\n",
      "Validation Loss: 0.7440890952430922\n",
      "Loaded 5032 word vectors.\n",
      "Number of training triplets: 3733\n",
      "[6,    31] loss: 0.791\n",
      "[6,    61] loss: 0.790\n",
      "[6,    91] loss: 0.747\n",
      "[6,   121] loss: 0.814\n",
      "[6,   151] loss: 0.749\n",
      "[6,   181] loss: 0.717\n",
      "[6,   211] loss: 0.743\n",
      "[6,   241] loss: 0.733\n",
      "[6,   271] loss: 0.730\n",
      "[6,   301] loss: 0.703\n",
      "[6,   331] loss: 0.673\n",
      "[6,   361] loss: 0.682\n",
      "[6,   391] loss: 0.758\n"
     ]
    }
   ],
   "source": [
    "net = SiameseNet.train(net, num_epochs, margin, lr, print_batch, \n",
    "                       data_dir_train, data_dir_val, writer_suffix, path_to_params, working_dir, class_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.5\n",
    "writer_suffix = 'allC1000_LRe-3_MR05'\n",
    "SiameseNet.val(net, margin, data_dir_val, writer_suffix, working_dir, class_dir, images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, ids, shape, description = SiameseNet.retrieval(net, data_dir_val, working_dir, print_nn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.retrieve_images(y_pred, ids, data_dir_val, class_dir, num_KNN=4, max_show=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = 'This is a black chair'\n",
    "sentence = input(\"Enter sentence\")\n",
    "utils.retrieve_one_sentence(net, data_dir_val, working_dir, sentence, class_dir, num_KNN=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
