{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/anaconda3/lib/python36.zip',\n",
       " '/anaconda3/lib/python3.6',\n",
       " '/anaconda3/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/anaconda3/lib/python3.6/site-packages',\n",
       " '/anaconda3/lib/python3.6/site-packages/aeosa',\n",
       " '/anaconda3/lib/python3.6/site-packages/pymesh2-0.2.1-py3.6-macosx-10.7-x86_64.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/NickHarmening/.ipython',\n",
       " '/usr/local/lib/python2.7/dist-packages',\n",
       " '/usr/local/lib/python3.5/dist-packages']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/dist-packages')\n",
    "sys.path.append('/usr/local/lib/python3.5/dist-packages')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_dict\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_name = '/data2'\n",
    "#create_dict.clean_obj(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 freeze | grep PyWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pywavefront\n",
    "#mesh2 = pywavefront.Wavefront('/home/.schramm/Documents/3d_retrieval/data/02747177/8bdea15ae5d929d0a2eb129d649f68cf/models/model_normalized.obj', collect_faces='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_folder = '/data'\n",
    "suffix = '_test_gpu2' #suffix will append data_trainxxxx.json\n",
    "max_elements_per_class = 5\n",
    "create_dict.create_dictionary(input_folder, max_elements_per_class, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SiameseNet\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 2\n",
    "net = SiameseNet.SiameseNet(batch_size)\n",
    "suffix = '_test' # comment in if not coming from generating the dataset\n",
    "path_to_params = \"models/testing.pt\" # if file does not exist or is empty it starts from untrained and later saves to the file\n",
    "\n",
    "# shift to GPU if available\n",
    "\n",
    "net.to(device)\n",
    "working_dir = os.getcwd()\n",
    "data_dir_train = os.path.join(working_dir, 'data_train'+suffix+'.json')\n",
    "data_dir_val = os.path.join(working_dir, 'data_val'+suffix+'.json')\n",
    "class_dir = os.path.join(working_dir, 'class_dict'+suffix+'.json')\n",
    "\n",
    "if os.path.isfile(path_to_params):\n",
    "    if os.stat(path_to_params).st_size != 0:\n",
    "        net.load_state_dict(torch.load(path_to_params))  #Loads pretrained net if file exists and if not empty\n",
    "else:\n",
    "    open(path_to_params, \"x\") #Creates parameter file if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#execute for tensorboard\n",
    "tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "writer_suffix = 'testing'\n",
    "margin = 0.5\n",
    "num_epochs = 1\n",
    "print_batch = 1\n",
    "lr = 0.0001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = SiameseNet.train(net, num_epochs, margin, lr, print_batch, \n",
    "                       data_dir_train, data_dir_val, writer_suffix, path_to_params, working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 val triplets generated\n",
      "Loaded 5032 word vectors.\n",
      "Number of validation triplets: 8\n",
      "Doing Evaluation\n",
      "0 [4 1 0 3 5]\n",
      "1 [4 1 0 3 5]\n",
      "2 [4 1 0 3 5]\n",
      "3 [4 1 0 3 5]\n",
      "4 [4 1 0 3 5]\n",
      "5 [4 1 0 3 5]\n",
      "6 [4 1 0 3 5]\n",
      "7 [4 1 0 3 5]\n",
      "precision: 0.625\n",
      "NDCG: 0.36855738985992403\n"
     ]
    }
   ],
   "source": [
    "margin = 0.5\n",
    "writer_suffix = 'Val'\n",
    "SiameseNet.val(net, margin, data_dir_val, writer_suffix, working_dir, class_dir, images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, ids, shape, description = SiameseNet.retrieval(net, data_dir_val, working_dir, print_nn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_KNN = 4\n",
    "max_show = 3\n",
    "utils.retrieve_images(y_pred, ids, data_dir_val, class_dir, num_KNN, max_show, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = 'This is a black chair'\n",
    "sentence = input(\"Enter sentence\")\n",
    "num_KNN = 4\n",
    "utils.retrieve_one_sentence(net, data_dir_val, working_dir, sentence, class_dir, num_KNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "name = str('images/' + '02747177' + '/' + '1b7d468a27208ee3dad910e221d16b18' + '/models/model_normalized.png')\n",
    "img = Image.open(name)\n",
    "#img = img.convert(\"RGB\")\n",
    "trans = transforms.ToTensor()\n",
    "tr = trans(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.load() # required for png.split()\n",
    "background = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "background.paste(img, mask=img.split()[3]) # 3 is the alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
