{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_dict\n",
    "import torch\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '/data'\n",
    "create_dict.clean_obj(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_folder = '/data'\n",
    "suffix = '_test' #suffix will append data_trainxxxx.json\n",
    "max_elements_per_class = 5\n",
    "create_dict.create_dictionary(input_folder, max_elements_per_class, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SiameseNet\n",
    "\n",
    "batch_size = 2\n",
    "net = SiameseNet.SiameseNet(batch_size)\n",
    "suffix = '_test' # comment in if not coming from generating the dataset\n",
    "\n",
    "\n",
    "path_to_params = \"models/test.pt\" # if file does not exist or is empty it starts from untrained and later saves to the file\n",
    "\n",
    "working_dir = os.getcwd()\n",
    "data_dir_train = os.path.join(working_dir, 'data_train'+suffix+'.json')\n",
    "data_dir_val = os.path.join(working_dir, 'data_val'+suffix+'.json')\n",
    "class_dir = os.path.join(working_dir, 'class_dict'+suffix+'.json')\n",
    "\n",
    "if os.path.isfile(path_to_params):\n",
    "    if os.stat(path_to_params).st_size != 0:\n",
    "        net.load_state_dict(torch.load(path_to_params))  #Loads pretrained net if file exists and if not empty\n",
    "else:\n",
    "    open(path_to_params, \"x\") #Creates parameter file if it does not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#execute for tensorboard\n",
    "tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "writer_suffix = 'testing'\n",
    "margin = 0.5\n",
    "num_epochs = 1\n",
    "print_batch = 1\n",
    "lr = 0.0001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = SiameseNet.train(net, num_epochs, margin, lr, print_batch, \n",
    "                       data_dir_train, data_dir_val, writer_suffix, path_to_params, working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 val triplets generated\n",
      "Loaded 5032 word vectors.\n",
      "Number of validation triplets: 4\n",
      "0 [2 5 3 7 1]\n",
      "1 [2 5 3 7 1]\n",
      "2 [2 5 3 7 1]\n",
      "3 [2 5 3 4 1]\n",
      "4 [2 5 3 7 1]\n",
      "5 [2 5 3 7 1]\n",
      "6 [2 5 3 7 1]\n",
      "7 [2 5 3 7 1]\n"
     ]
    }
   ],
   "source": [
    "writer_suffix = 'Val'\n",
    "margin = 0.5\n",
    "\n",
    "y_true, y_pred, ids, shape, description = SiameseNet.retrieval(net, data_dir_val, working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: ID: cb38405e384c79c05e4e385b035691bb  Description: ['this', 'is', 'a', 'brown', 'tub']\n",
      "1N: ID 2388c99892c2185268d1b9a1d97e2846\n",
      "2N: ID e5b583b0cf478984d781754d41e2576e\n",
      "Sample: ID: 555f9430c2ca273ccb2a965e75be701c  Description: ['this', 'is', 'a', 'brown', 'and', 'red', 'table']\n",
      "1N: ID 2388c99892c2185268d1b9a1d97e2846\n",
      "2N: ID e5b583b0cf478984d781754d41e2576e\n",
      "Sample: ID: 2388c99892c2185268d1b9a1d97e2846  Description: ['this', 'is', 'up', 'lamp', 'around', 'a', 'blue', 'pole', 'with', 'no', 'lamp', 'shade']\n",
      "1N: ID 2388c99892c2185268d1b9a1d97e2846\n",
      "2N: ID e5b583b0cf478984d781754d41e2576e\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir_val, 'r') as fp:\n",
    "    data_val = json.load(fp)\n",
    "\n",
    "max_show = 3\n",
    "for i, key in enumerate(ids):\n",
    "    if (i>=max_show):\n",
    "        break\n",
    "    print(\"Sample: ID:\", key, \" Description:\", data_val[key][1])\n",
    "    print(\"1N: ID\", ids[y_pred[i][0]]) #todo get picture\n",
    "    print(\"2N: ID\", ids[y_pred[i][1]]) #todo get picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
